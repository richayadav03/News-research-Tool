{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72ed1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3a53c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342107a",
   "metadata": {},
   "source": [
    "# User-Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d47eb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"News research Tool\")\n",
    "st.sidebar.title(\"News Article URLs\")\n",
    "\n",
    "for i in range(3):\n",
    "    st.sidebar.text_input(f\"URL {i+1}\")\n",
    "    \n",
    "process=st.sidebar.button(\"Process URLs\")    \n",
    "\n",
    "if process:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03f0ad89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%streamlit` not found.\n"
     ]
    }
   ],
   "source": [
    "# %run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d3741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b5347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e60bf17",
   "metadata": {},
   "source": [
    "# Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f2fae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14c3dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=TextLoader(\"nvidia.txt\")\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74eab688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'nvidia.txt'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "003464fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting unstructured\n",
      "  Downloading unstructured-0.13.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting libmagic\n",
      "  Downloading libmagic-1.0.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting python-magic-bin\n",
      "  Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl.metadata (710 bytes)\n",
      "Requirement already satisfied: chardet in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (5.1.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (4.9.1)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (3.7)\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (0.8.10)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (4.11.1)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.11.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (0.6.4)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 337.9/981.5 kB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------  972.8/981.5 kB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 8.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (1.23.5)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.8.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from unstructured) (4.11.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.22.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: wrapt in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->unstructured) (2.3.2.post1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from dataclasses-json->unstructured) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->unstructured) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->unstructured) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->unstructured) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->unstructured) (2022.12.7)\n",
      "Collecting certifi>=2017.4.17 (from requests->unstructured)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.21.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "  Downloading unstructured_client-0.21.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Downloading unstructured_client-0.18.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.17.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.16.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.15.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.15.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "INFO: pip is still looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading unstructured_client-0.15.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.15.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.14.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.14.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading unstructured_client-0.12.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading unstructured_client-0.12.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Downloading unstructured_client-0.8.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting charset-normalizer<3,>=2 (from requests->unstructured)\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting marshmallow-enum>=1.5.1 (from unstructured-client->unstructured)\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (0.4.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from unstructured-client->unstructured) (23.2)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Downloading unstructured-0.13.3-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.9 MB 93.9 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.0/1.9 MB 93.9 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.0/1.9 MB 93.9 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.0/1.9 MB 85.6 kB/s eta 0:00:22\n",
      "    --------------------------------------- 0.0/1.9 MB 85.6 kB/s eta 0:00:22\n",
      "   - -------------------------------------- 0.1/1.9 MB 109.4 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.1/1.9 MB 109.4 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.1/1.9 MB 131.3 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.1/1.9 MB 138.1 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.1/1.9 MB 160.0 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.1/1.9 MB 164.0 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.2/1.9 MB 204.8 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 231.6 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 259.7 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 309.9 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.3/1.9 MB 368.2 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 489.1 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.6/1.9 MB 577.6 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 719.1 kB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 876.7 kB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/1.9 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_magic_bin-0.4.14-py2.py3-none-win_amd64.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.3 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 122.9/409.3 kB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 317.4/409.3 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.3/409.3 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
      "   ---------------------------------------- 0.0/433.8 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 307.2/433.8 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 433.8/433.8 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 266.2/274.7 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.7/274.7 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading rapidfuzz-3.8.1-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.2/1.7 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.6/1.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.8.1-py3-none-any.whl (19 kB)\n",
      "Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Building wheels for collected packages: libmagic, langdetect\n",
      "  Building wheel for libmagic (setup.py): started\n",
      "  Building wheel for libmagic (setup.py): finished with status 'done'\n",
      "  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4277 sha256=f433419d76be00a8e1cdb7912653fd39d6cab0226e60b6416c137632b0a8231f\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\31\\ce\\d8\\099fbd4dbfa5da5596a39eee8a17d2e1bcc29006c07d3563b7\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=3278a16ffbd9cdf5f6908d2d65a804914a9d3fe51d400aa1e80c2848cf0753a7\n",
      "  Stored in directory: c:\\users\\asus\\appdata\\local\\pip\\cache\\wheels\\95\\03\\7d\\59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built libmagic langdetect\n",
      "Installing collected packages: python-magic-bin, libmagic, filetype, rapidfuzz, python-magic, python-iso639, langdetect, jsonpath-python, emoji, charset-normalizer, backoff, marshmallow-enum, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 charset-normalizer-2.1.1 emoji-2.11.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 libmagic-1.0 marshmallow-enum-1.5.1 python-iso639-2024.2.7 python-magic-0.4.27 python-magic-bin-0.4.14 rapidfuzz-3.8.1 unstructured-0.13.3 unstructured-client-0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "  WARNING: The script filetype.exe is installed in 'C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script unstructured-ingest.exe is installed in 'C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured libmagic python-magic python-magic-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "313d749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d8f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=UnstructuredURLLoader(urls=[\"https://www.coursera.org/articles/what-is-data-analysis-with-examples\",\n",
    "                           \"https://www.coursera.org/in/articles/what-does-a-data-analyst-do-a-career-guide\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4772f9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7de7913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://www.coursera.org/articles/what-is-data-analysis-with-examples'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc827b",
   "metadata": {},
   "source": [
    "# Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ecbdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random text from wikipedia\n",
    "\n",
    "text='''Oppenheimer is a 2023 epic biographical thriller film[a] written, directed, and produced by Christopher Nolan.[8] It follows the life of J. Robert Oppenheimer, the American theoretical physicist who helped develop the first nuclear weapons during World War II. Based on the 2005 biography American Prometheus by Kai Bird and Martin J. Sherwin, the film chronicles Oppenheimer's studies, his direction of the Los Alamos Laboratory, and his fall from grace after his 1954 security hearing. Cillian Murphy stars as Oppenheimer, alongside Robert Downey Jr. as the United States Atomic Energy Commission member Lewis Strauss. The ensemble supporting cast includes Emily Blunt, Matt Damon, Florence Pugh, Josh Hartnett, Casey Affleck, Rami Malek and Kenneth Branagh.\n",
    "\n",
    "Oppenheimer was announced in September 2021. It is Nolan's first film not distributed by Warner Bros. Pictures since Memento (2000), due to his conflicts regarding the studio's simultaneous theatrical and HBO Max release schedule.[9] Murphy was the first cast member to sign on the following month, with the rest joining between November 2021 and April 2022. Pre-production began by January 2022, and filming took place from February to May. The cinematographer, Hoyte van Hoytema, used a combination of IMAX 65 mm and 65 mm large-format film, including, for the first time, scenes in IMAX black-and-white film photography. As with many of his previous films, Nolan used extensive practical effects, with minimal compositing.\n",
    "\n",
    "Oppenheimer premiered at Le Grand Rex in Paris on July 11, 2023, and was theatrically released in the US and the UK ten days later by Universal. Its concurrent release with Warner Bros.'s Barbie was the catalyst of the \"Barbenheimer\" phenomenon, encouraging audiences to see both films as a double feature. Oppenheimer grossed $970 million worldwide, becoming the third-highest-grossing film of 2023, the highest-grossing World War II-related film, the highest-grossing biographical film and the second-highest-grossing R-rated film.\n",
    "\n",
    "Among its many accolades, Oppenheimer won seven Academy Awards, including Best Picture, Best Director, Best Actor for Murphy and Best Supporting Actor for Downey. It also won five Golden Globe Awards (including Best Motion Picture – Drama) and seven British Academy Film Awards (including Best Film), and was named one of the top ten films of 2023 by the National Board of Review and the American Film Institute.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd4998",
   "metadata": {},
   "source": [
    "# Why Langchain is used?\n",
    "'Slice' operator may cut down words, 'for loop' is not suitable for bigger chunks data. on the other hand, Langchain provides an API so manual worl is limited down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac0cef8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oppenheimer is a 2023 epic biographical thriller film[a] written, directed, and produced by Christopher Nolan.[8] It follows the life of J. Robert Oppenheimer, the American theoretical physicist who h'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a8d4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter=CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58cb45df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 760, which is longer than the specified 200\n",
      "Created a chunk of size 725, which is longer than the specified 200\n",
      "Created a chunk of size 533, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=splitter.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6c52c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Oppenheimer is a 2023 epic biographical thriller film[a] written, directed, and produced by Christopher Nolan.[8] It follows the life of J. Robert Oppenheimer, the American theoretical physicist who helped develop the first nuclear weapons during World War II. Based on the 2005 biography American Prometheus by Kai Bird and Martin J. Sherwin, the film chronicles Oppenheimer's studies, his direction of the Los Alamos Laboratory, and his fall from grace after his 1954 security hearing. Cillian Murphy stars as Oppenheimer, alongside Robert Downey Jr. as the United States Atomic Energy Commission member Lewis Strauss. The ensemble supporting cast includes Emily Blunt, Matt Damon, Florence Pugh, Josh Hartnett, Casey Affleck, Rami Malek and Kenneth Branagh.\",\n",
       " \"Oppenheimer was announced in September 2021. It is Nolan's first film not distributed by Warner Bros. Pictures since Memento (2000), due to his conflicts regarding the studio's simultaneous theatrical and HBO Max release schedule.[9] Murphy was the first cast member to sign on the following month, with the rest joining between November 2021 and April 2022. Pre-production began by January 2022, and filming took place from February to May. The cinematographer, Hoyte van Hoytema, used a combination of IMAX 65 mm and 65 mm large-format film, including, for the first time, scenes in IMAX black-and-white film photography. As with many of his previous films, Nolan used extensive practical effects, with minimal compositing.\",\n",
       " 'Oppenheimer premiered at Le Grand Rex in Paris on July 11, 2023, and was theatrically released in the US and the UK ten days later by Universal. Its concurrent release with Warner Bros.\\'s Barbie was the catalyst of the \"Barbenheimer\" phenomenon, encouraging audiences to see both films as a double feature. Oppenheimer grossed $970 million worldwide, becoming the third-highest-grossing film of 2023, the highest-grossing World War II-related film, the highest-grossing biographical film and the second-highest-grossing R-rated film.',\n",
       " 'Among its many accolades, Oppenheimer won seven Academy Awards, including Best Picture, Best Director, Best Actor for Murphy and Best Supporting Actor for Downey. It also won five Golden Globe Awards (including Best Motion Picture – Drama) and seven British Academy Film Awards (including Best Film), and was named one of the top ten films of 2023 by the National Board of Review and the American Film Institute.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9eb75eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760\n",
      "725\n",
      "533\n",
      "412\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e739c97",
   "metadata": {},
   "source": [
    "## To avoid exceeding the chunk size limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71ec059e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive=splitter=RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"],\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks=recursive.split_text(text)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbc8fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "191\n",
      "196\n",
      "172\n",
      "189\n",
      "192\n",
      "198\n",
      "143\n",
      "198\n",
      "195\n",
      "138\n",
      "199\n",
      "196\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d9cea",
   "metadata": {},
   "source": [
    "# FAISS Index - Facebook AI Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59ea5ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (1.23.5)\n",
      "Downloading faiss_cpu-1.8.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.5 MB 9.2 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.5/14.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 11.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.8/14.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.3/14.5 MB 11.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.9/14.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.6/14.5 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.8/14.5 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.6/14.5 MB 12.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.4/14.5 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.2/14.5 MB 13.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.9/14.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 8.9/14.5 MB 13.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.4/14.5 MB 13.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.9/14.5 MB 13.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.4/14.5 MB 14.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.2/14.5 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.4/14.5 MB 14.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 14.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 14.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 13.1 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (0.19.3)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/171.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 171.5/171.5 kB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorboard (c:\\users\\asus\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373e910",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
